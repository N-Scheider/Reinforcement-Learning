{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db3e6c3-1008-4cb9-b13b-1a1295b76e9b",
   "metadata": {},
   "source": [
    "#  Mathematics of Reinforcement Learning: Homework Sheet 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401c27c",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "The theoretical exercise 1 can be found in the PDF file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e99cb",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "In this exercise we use the Bellman optimality equation to compute the optimal policy in the optimal investment problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891cb51-d3be-4a81-ac6f-087af1a88555",
   "metadata": {},
   "source": [
    "Make sure you have all the necessary packages (numpy, matplotlib) installed. You can use `conda install <package>` or `pip install <package>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45876d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c234faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the start state, which will be used in some test functions.\n",
    "start_state = (0., 8., 100.)\n",
    "\n",
    "#market parameters\n",
    "T = 3     #Time horizon\n",
    "u = 1.0   #CRR parameter, up factor change, slightly different from the other exercises!\n",
    "d = -.5   #CRR parameter, down factor change\n",
    "q = .5    #CRR parameter, probability of up change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43fa71",
   "metadata": {},
   "source": [
    "**Task 1:** Implement a function `get_admissible_actions(p, w)` that takes as input float values `p` and `w` representing the current asset price `p` and wealth `w` and returns a list of all possible action values in the form of float values.\n",
    "\n",
    "*Reminder:* It is only possible to buy integer amounts of the financial asset. The amount must be non-negative and can't exceed the current wealth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ada537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_admissible_actions(p, w):\n",
    "    \n",
    "    max_num_assets = int(np.floor(w/p))\n",
    "    \n",
    "    return [p * i for i in range(max_num_assets + 1)]\n",
    "\n",
    "assert get_admissible_actions(10,20) == [0,10,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd4e56",
   "metadata": {},
   "source": [
    "**Task 2:** Implement a function `get_all_states()` that returns a list of all possible states in the Optimal Investment Markov Decision Model up to the timepoint `T` in the form of tuples. The structure of the tuple should be `(timestep, asset_price, wealth)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93541d34-f976-4f77-8e69-0d02f032d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30545\n",
      "Number of calculated states: 482. This number should be equal to 482\n"
     ]
    }
   ],
   "source": [
    "def get_all_states():\n",
    "    states = [start_state]\n",
    "    \n",
    "    for state in states:\n",
    "        if state[0] < T:\n",
    "            for a in get_admissible_actions(state[1],state[2]):\n",
    "                for R in [d,u]:\n",
    "                    \n",
    "                    new_state = ( state[0] + 1,\n",
    "                                  state[1] * (1+R),\n",
    "                                  state[2] + R * a\n",
    "                                )\n",
    "                    states.append(new_state)\n",
    "    return states\n",
    "\n",
    "states = get_all_states()\n",
    "print(len(states))\n",
    "# remove duplicate states\n",
    "states = list(set(states))\n",
    "print(f'Number of calculated states: {len(states)}. This number should be equal to 482')\n",
    "assert len(states) == 482"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c3022",
   "metadata": {},
   "source": [
    "**Task 3:** Implement a function `bellman_optimality_equation(states)` that takes as input the list of all possible states and returns a dictionary, where the keys are all possible states (in form of tuples), and the value for each key is a dictionary containing the optimal action and the value of that state (with string keys `\"opt_a\"` and `\"V\"`) computed with the Bellman optimality equation given in Exercise 1.\n",
    "\n",
    "*Hints:*\n",
    "1. Start by computing the value function of all terminal wealths (the optimal action can be set to `None`).\n",
    "2. Working backwards in time, starting at time `t = T-1`, iterate over all states with timepoint `t`, then iterate over all admissible actions and compute the value following that action. The optimal action is the action with the highest expected value in the next state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dd6a91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value_t_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m                 bellman_dict[state] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt_a\u001b[39m\u001b[38;5;124m\"\u001b[39m : opt_a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m : V}\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bellman_dict\n\u001b[0;32m---> 37\u001b[0m bellman_dict \u001b[38;5;241m=\u001b[39m \u001b[43mbellman_optimality_equation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#Test function\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m bellman_dict[start_state][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt_a\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m48.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mbellman_optimality_equation\u001b[0;34m(states)\u001b[0m\n\u001b[1;32m     28\u001b[0m         V \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m     29\u001b[0m         opt_a \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m---> 32\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[43mvalue_t_a\u001b[49m)\n\u001b[1;32m     33\u001b[0m opt_a \u001b[38;5;241m=\u001b[39m value_t_a\u001b[38;5;241m.\u001b[39mindex(V)\n\u001b[1;32m     34\u001b[0m bellman_dict[state] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt_a\u001b[39m\u001b[38;5;124m\"\u001b[39m : opt_a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m : V}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'value_t_a' is not defined"
     ]
    }
   ],
   "source": [
    "def bellman_optimality_equation(states):\n",
    "    \n",
    "    bellman_dict = {}\n",
    "    \n",
    "    for state in states:\n",
    "        if state[0] == T:\n",
    "            bellman_dict[state] = {\"opt_a\" : None, \"V\" : np.log(state[2])}\n",
    "    \n",
    "    for t in range(T-1,-1,-1):\n",
    "        for state in states:\n",
    "            if state[0] == t:\n",
    "                opt_a = None\n",
    "                V = -np.inf\n",
    "                \n",
    "                for a in get_admissible_actions(state[1], state[2]):\n",
    "                    next_state_1 = (state[0] + 1,\n",
    "                                  state[1] * (1 + u),\n",
    "                                  state[2] + u * a\n",
    "                                )\n",
    "                    next_state_2 = ( state[0] + 1,\n",
    "                                  state[1] * (1 + d),\n",
    "                                  state[2] + d * a\n",
    "                                )\n",
    "                    value = q * bellman_dict[next_state_1][\"V\"] + \\\n",
    "                            (1-q) * bellman_dict[next_state_2][\"V\"]\n",
    "                        \n",
    "                    if value > V:\n",
    "                        V = value\n",
    "                        opt_a = a\n",
    "                \n",
    "\n",
    "                V = max(value_t_a)\n",
    "                opt_a = value_t_a.index(V)\n",
    "                bellman_dict[state] = {\"opt_a\" : opt_a, \"V\" : V}\n",
    "    return bellman_dict\n",
    "    \n",
    "bellman_dict = bellman_optimality_equation(states)\n",
    "\n",
    "#Test function\n",
    "assert bellman_dict[start_state]['opt_a'] == 48.0\n",
    "assert np.isclose(bellman_dict[start_state]['V'], 4.781250991199082)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53023c0",
   "metadata": {},
   "source": [
    "**Task 4:** Visualise the optimal strategy. To do this, create a Matplotlib scatter plot with the current wealth on the x-axis and the amount of  money invested in the financial asset on the y-axis. First, plot all possible wealth action pairs. Next, highlight the optimal wealth action pairs. \n",
    "\n",
    "Try to reproduce Figure 1.5 from the script. The formula for the black line in Figure 1.5 is given by\n",
    "    $$\\mathrm{black line}(w) = \\left(-\\frac{q}{d}-\\frac{1-q}{u}\\right) \\cdot w.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_states = []\n",
    "plot_states_opt = []\n",
    "min_wealth = + np.inf\n",
    "max_wealth = - np.inf\n",
    "for state in states:\n",
    "    for action in get_admissible_actions(p = state[1], w = state[2]):\n",
    "        if state[0] < T:\n",
    "            plot_states.append((state[2],action))\n",
    "            if action == bellman_dict[state][\"opt_a\"]:\n",
    "                plot_states_opt.append((state[2],action))\n",
    "            if min_wealth > state[2]:\n",
    "                min_wealth = state[2]\n",
    "            if max_wealth < state[2]:\n",
    "                max_wealth = state[2]\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(*zip(*plot_states), c='#0065bd')\n",
    "ax.scatter(*zip(*plot_states_opt), c='#F7811E')\n",
    "opt_frac = -q/d-(1-q)/u\n",
    "ax.plot([min_wealth, max_wealth], [opt_frac*min_wealth, opt_frac*max_wealth], c='black')\n",
    "plt.xlabel(\"Total Wealth\")\n",
    "plt.ylabel(\"Wealth in Financial Asset\")\n",
    "plt.savefig(\"opt_policy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c8cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5213d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab319d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe88e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc4318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e78a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
